{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoModel, AutoTokenizer\n",
    "from torch.nn import Module\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "##st_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#st_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "\n",
    "class inspect_func(Module):\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        pprint(args)\n",
    "        pprint(kwargs)\n",
    "        print(kwargs[\"encoder_hidden_states\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3171, -0.0024,  0.6244,  ...,  0.3232, -0.1514, -0.2152],\n",
      "         [ 0.1937,  0.0800,  0.5210,  ...,  0.5329,  0.1537,  0.0716],\n",
      "         [ 0.9578,  0.6989,  0.2488,  ...,  0.3102,  0.1141, -0.0484],\n",
      "         ...,\n",
      "         [-0.2485,  0.2961,  0.3823,  ...,  0.3827,  0.2004, -0.4977],\n",
      "         [ 0.3643, -0.0698,  0.0736,  ...,  0.5198,  0.1275, -0.3185],\n",
      "         [ 0.1206,  0.1841,  0.2435,  ...,  0.3209,  0.1520, -0.1109]],\n",
      "\n",
      "        [[ 0.1973,  0.0898,  0.0544,  ...,  0.5683, -0.3024,  0.1424],\n",
      "         [ 0.6744,  0.4258, -0.0365,  ...,  0.5554, -0.0285, -0.0414],\n",
      "         [-0.0486, -0.1381,  0.0093,  ...,  0.6076,  0.0589,  0.1301],\n",
      "         ...,\n",
      "         [ 0.0136,  0.1186, -0.0105,  ...,  0.5485, -0.1306,  0.0441],\n",
      "         [ 0.2659,  0.0137,  0.0820,  ...,  0.6097, -0.2816,  0.1907],\n",
      "         [ 0.1904,  0.0573,  0.0702,  ...,  0.6156, -0.3170,  0.2227]],\n",
      "\n",
      "        [[-0.4076,  0.0368,  0.1900,  ...,  0.0402,  0.0281, -0.1651],\n",
      "         [-0.6842, -0.0554, -0.0106,  ...,  0.1736,  0.1461, -0.2830],\n",
      "         [-0.6724, -0.3521,  0.1115,  ...,  0.1164,  0.0881, -0.2416],\n",
      "         ...,\n",
      "         [-0.5585, -0.1474,  0.0984,  ...,  0.2258,  0.2083, -0.2701],\n",
      "         [-0.0984,  0.1312,  0.0602,  ...,  0.0852, -0.0332, -0.0075],\n",
      "         [-0.2971,  0.1232,  0.1416,  ...,  0.1467,  0.0761,  0.0026]]]), pooler_output=tensor([[ 0.0111, -0.1399,  0.4512,  ..., -0.0541,  0.1625, -0.0399],\n",
      "        [ 0.1411,  0.0426,  0.0804,  ...,  0.0977,  0.1479, -0.1385],\n",
      "        [ 0.2725, -0.1882,  0.3188,  ...,  0.1282, -0.1013,  0.2694]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "st_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\") #model_args={\"embedding_size\":512})\n",
    "st_model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\")#embedding_size=512)\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = st_tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = st_model(**encoded_input)\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "print(model_output[\"pooler_output\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 30522,  7592, 30522,  7592, 30522,  6251,  1017,   102]])\n",
      "['', ' hello ', ' hello ', ' sentence 3']\n",
      "tensor([[ 0.3442, -0.1094,  0.0149,  ..., -0.0259,  0.1215,  0.0161],\n",
      "        [ 0.3086, -0.1528, -0.0263,  ...,  0.0507,  0.0554, -0.0689],\n",
      "        [ 0.3086, -0.1528, -0.0263,  ...,  0.0507,  0.0554, -0.0689],\n",
      "        [ 0.4801, -0.0923,  0.2168,  ...,  0.0564,  0.0845, -0.2599]])\n",
      "torch.Size([4, 768])\n",
      "tensor([[[ 0.3442, -0.1094,  0.0149,  ..., -0.0259,  0.1215,  0.0161],\n",
      "         [ 0.3086, -0.1528, -0.0263,  ...,  0.0507,  0.0554, -0.0689],\n",
      "         [ 0.3086, -0.1528, -0.0263,  ...,  0.0507,  0.0554, -0.0689],\n",
      "         [ 0.4801, -0.0923,  0.2168,  ...,  0.0564,  0.0845, -0.2599]]])\n",
      "torch.Size([1, 4, 768])\n",
      "{'attention_mask': tensor([[1., 1., 1., 1.]]),\n",
      " 'output_attentions': False,\n",
      " 'output_hidden_states': False,\n",
      " 'return_dict': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 2, 3, 2, 3, 2, 3, 7, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def concat_dicts(dict_1, dict_2):\n",
    "    for k in dict_1:\n",
    "        dict_1[k] = torch.cat((dict_1[k], dict_2[k]),dim=1)\n",
    "    return dict_1\n",
    "\n",
    "\n",
    "\n",
    "class STOnlyEncoder(Module):\n",
    "    def __init__(self, encoder, tokenizer, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.st_encoder = encoder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.extra_token_id = self.tokenizer.encode(\"<extra_id_0>\")[1]\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "\n",
    "\n",
    "        batches = []\n",
    "\n",
    "        for b in input_ids:\n",
    "            text = self.tokenizer.decode(b, ignore_special_tokens=True)[5:-5]\n",
    "            text = text.strip(\" \")\n",
    "            sents = text.split(\"<extra_id_0>\")\n",
    "            sents_tokenized = self.tokenizer.batch_encode_plus(sents, return_tensors=\"pt\", padding=True)\n",
    "            \n",
    "            encoded = self.st_encoder.forward(**sents_tokenized)\n",
    "            pooler_output = encoded[\"pooler_output\"]\n",
    "            print(sents)\n",
    "            print(pooler_output)\n",
    "            print(pooler_output.shape)\n",
    "            batches.append(pooler_output)\n",
    "        \n",
    "        embeddings = pad_sequence(batches, batch_first=True)\n",
    "        print(embeddings)\n",
    "        print(embeddings.size())\n",
    "        output = BaseModelOutputWithPastAndCrossAttentions(embeddings, )\n",
    "        pprint(kwargs)\n",
    " #       encoded = self.st_encoder.forward(input_ids, **kwargs)\n",
    "#        pooler_output = encoded[\"pooler_output\"]\n",
    "\n",
    "        return output\n",
    "        \n",
    "\n",
    "class CustomEncoder(Module):\n",
    "    def __init__(self, encoder, *args, **kwargs):    \n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.t5_encoder = encoder\n",
    "\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        print(\"kwargs\")\n",
    "        print(kwargs)\n",
    "\n",
    "        input_ids = input_ids[:input_ids.shape[0],:input_ids.shape[1]//2]\n",
    "        kwargs[\"attention_mask\"] = kwargs[\"attention_mask\"][:input_ids.shape[0], :input_ids.shape[1]]\n",
    "        encoder_1_output = self.t5_encoder.forward(input_ids, **kwargs)\n",
    "        encoder_2_output = self.t5_encoder.forward(input_ids, **kwargs)\n",
    "        print(\"input ids shape\",input_ids.shape)\n",
    "        print(\"attention mask shape\", kwargs[\"attention_mask\"].shape)\n",
    "        print(encoder_1_output[\"last_hidden_state\"].shape)\n",
    "\n",
    "        encoder_output = concat_dicts(encoder_1_output, encoder_2_output)\n",
    "        print(dir(encoder_1_output))\n",
    "        #print(encoder_output)\n",
    "        print(encoder_output[\"last_hidden_state\"].shape)\n",
    "\n",
    "        print(encoder_output)\n",
    "\n",
    "        pprint(kwargs)\n",
    "        return(encoder_output)\n",
    "\n",
    "\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "import re\n",
    "\n",
    "\n",
    "def replace_newlines(text):\n",
    "    text = re.sub(\"[\\n\\W]*\\n[\\n\\W]*\", \"<extra_id_0>\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "example_dialogue = \"\\nhello\\nhello\\n\\nsentence 3\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\", extra_ids=1)\n",
    "\n",
    "st_tokenizer.add_tokens(['<extra_id_0>'], special_tokens=True) ##This line is updated\n",
    "st_model.resize_token_embeddings(len(tokenizer))\n",
    "st_only_encoder = STOnlyEncoder(st_model,st_tokenizer)\n",
    "\n",
    "t5_model.encoder = st_only_encoder\n",
    "\n",
    "#t5_model.encoder = CustomEncoder(t5_model.encoder)\n",
    "\n",
    "\n",
    "\n",
    "st_tokens = st_tokenizer.encode(replace_newlines(example_dialogue), return_tensors=\"pt\")\n",
    "\n",
    "    \n",
    "print(st_tokens)\n",
    "t5_model.generate(st_tokens, attention_mask=torch.Tensor([[1]*4]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> <unk> <unk> <unk> s a a a a a'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_tokenizer.decode(torch.Tensor([0, 3, 2, 3, 2, 3, 2, 3, 7, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here ', ' are ', ' some ', ' sentences']\n",
      "tensor([[ 0.3270,  0.2870, -0.1443,  ...,  0.0487,  0.0666, -0.0639],\n",
      "        [ 0.1175,  0.0292, -0.1062,  ...,  0.0180,  0.1735,  0.0575],\n",
      "        [ 0.1774, -0.0870, -0.2180,  ...,  0.0631,  0.2605,  0.1801],\n",
      "        [ 0.1744, -0.1681,  0.0668,  ...,  0.0326,  0.0542, -0.1686]])\n",
      "torch.Size([4, 768])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Make sure that `model_kwargs` include `encoder_outputs` of type `ModelOutput`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40157120e46c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mst_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_newlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt5_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"encoder_outputs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure that `model_kwargs` include `encoder_outputs` of type `ModelOutput`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# if `max_new_tokens` is passed, but not `max_length` -> set `max_length = max_new_tokens`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Make sure that `model_kwargs` include `encoder_outputs` of type `ModelOutput`."
     ]
    }
   ],
   "source": [
    "words = \"here \\n are \\n some \\n sentences\"\n",
    "st_tokens = st_tokenizer.encode(replace_newlines(words), return_tensors=\"pt\")\n",
    "\n",
    "t5_model.generate(st_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30355,    15,    12,  2968,    10,   100,    19,    46,    73,   864,\n",
      "           739,  3834,   307,  7142,     1]])\n",
      "kwargs\n",
      "{'return_dict': True, 'output_attentions': False, 'output_hidden_states': False, 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "input ids shape torch.Size([1, 15])\n",
      "attention mask shape torch.Size([1, 15])\n",
      "torch.Size([1, 15, 768])\n",
      "['__annotations__', '__class__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'cross_attentions', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'last_hidden_state', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n",
      "torch.Size([1, 30, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<extra_id_-99>: This is an unreasonably long sentence.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"Translate to German: This is an unreasonably long sentence\", return_tensors=\"pt\")\n",
    "print(tokens)\n",
    "tokens = torch.cat((tokens, tokens), dim=1)\n",
    "generated = model.generate(tokens)\n",
    "tokenizer.decode(generated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30355,    15,    12,  2968,    10,   100,    19,    46,    73,   864,\n",
       "           739,  3834,   307,  7142,     1, 30355,    15,    12,  2968,    10,\n",
       "           100,    19,    46,    73,   864,   739,  3834,   307,  7142,     1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs\n",
      "{'attention_mask': None, 'inputs_embeds': None, 'head_mask': None, 'output_attentions': None, 'output_hidden_states': None, 'return_dict': True}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5da7173f5c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1572\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6601f933bfaf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mencoder_1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt5_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mencoder_2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt5_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.forward(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_generated = t5_model.generate(tokens)\n",
    "tokenizer.decode(t5_generated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.generate(tokens)\n",
    "tokenizer.decode(generated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model.forward(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
