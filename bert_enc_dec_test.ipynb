{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--MODEL MODEL]\n",
      "                             [--TRAIN_EPOCHS TRAIN_EPOCHS]\n",
      "                             [--PRETRAIN_EPOCHS PRETRAIN_EPOCHS]\n",
      "                             [--LEARNING_RATE LEARNING_RATE]\n",
      "                             [--RUN_NAME RUN_NAME] [--BATCH_SIZE BATCH_SIZE]\n",
      "                             [--MODEL_TYPE MODEL_TYPE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"86717888-0112-4cb6-ada7-fb065b05e693\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=/tmp/tmp-10234Hk13R2Bw7ide.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from experimental.enc_dec_dataset import EncDecDataset, CustomEncoder\n",
    "from experimental.enc_dec_training import EncDecTrainer\n",
    "import json\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\", pad_token_id=0)\n",
    "#orig_model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\", pad_token_id=0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\", pad_token_id=0)\n",
    "cust_enc = CustomEncoder(model.encoder)\n",
    "model.encoder = cust_enc\n",
    "#cust_dec = CustomDecoder(model.decoder)\n",
    "\n",
    "model.encoder = cust_enc\n",
    "\n",
    "\n",
    "DATA_DIR = \"DialogSum_Data\"\n",
    "\n",
    "SAMPLE_DATA = op.join(DATA_DIR, 'dialogsum.sample.jsonl')\n",
    "TEST_DATA = op.join(DATA_DIR, 'dialogsum.test.jsonl')\n",
    "TRAIN_DATA = op.join(DATA_DIR, 'dialogsum.train.jsonl')\n",
    "DEV_DATA = op.join(DATA_DIR, 'dialogsum.dev.jsonl')\n",
    "\n",
    "def load_jsonl(filepath):\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    with open(filepath) as sd_file:\n",
    "        lines = sd_file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        output_list.append(json.loads(line))\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model_params = {\n",
    "        \"MODEL\": args.MODEL,  # model_type: t5-base/t5-large\n",
    "        \"TRAIN_BATCH_SIZE\": 1,  # training batch size\n",
    "        \"VALID_BATCH_SIZE\": 1,  # validation batch size\n",
    "        \"TRAIN_EPOCHS\":  1,  # number of training epochs\n",
    "        \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
    "        \"LEARNING_RATE\": 1e-3,  # learning rate\n",
    "        #\"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "        #\"MAX_TARGET_TEXT_LENGTH\": 50,  # max length of target text\n",
    "        \"SEED\": 42,  # set seed for reproducibility\n",
    "        }\n",
    "\n",
    "\n",
    "    dev_data_list = load_jsonl(DEV_DATA)\n",
    "    dev_dataset = EncDecDataset(dev_data_list, \n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "    train_data_list = load_jsonl(TRAIN_DATA)\n",
    "    train_dataset = EncDecDataset(train_data_list,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "    model = EncDecTrainer(train_dataset=train_dataset, val_dataset=dev_dataset,\n",
    "                    model=model, tokenizer=tokenizer, model_params=model_params)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21b5f0ea4c5d1d5452f540f8b826290a2ddfb797a39b03c535ea5a8419c7448b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dialogsum-cdt-challenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
